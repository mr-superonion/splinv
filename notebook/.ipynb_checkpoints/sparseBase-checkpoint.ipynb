{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General LASSO\n",
    "\n",
    "$$L(\\vec{x})=\\frac{1}{2}(y_{i}-A^{*}_{ij}x_{j})(y_{i}-A_{ik}x_{k})+\\frac{\\lambda_2}{2}[(D^{1}_{ij} x_{j})(D^{1}_{ik}x_{k})+ (D^{2}_{ij} x_{j})(D^{2}_{ik}x_{k})]+ \\lambda_1 \\sigma_i |x_i|,$$\n",
    "\n",
    "where $x_i$ is the i-th component of real vector $\\vec{x}$, $A_{ij}$ and $D^{1,2}_{ij}$ are the $(i,j)$ component of matrix $\\mathbf{A}$ and $\\mathbf{D^{1,2}}$. $A_{ij}$ is complex number whereas $D^{1,2}_{ij}$ are real number. $A^{*}_{ij}$ is used to denote the conjugate of $A_{ij}$.\n",
    "\n",
    "$\\mathbf{A}$ refers to the transformation operator from the real dictionary field to the observed complex shear field. Note that we do not consider $B$ mode so $x$ is a real vector. \n",
    "\n",
    "```python\n",
    "# sparseBase.massmapSparsityTask.__init__\n",
    "## Initialization of the Dictionary Space (A)\n",
    "# 1) Basis vector used to model the Surface Density of halo  \n",
    "if dicname=='starlet':\n",
    "    from halolet import starlet2D\n",
    "    self.dict2D =   starlet2D(gen=2,nframe=self.nframe,ny=self.ny,nx=self.nx)\n",
    "elif dicname=='nfwlet':\n",
    "    from halolet import nfwlet2D\n",
    "    self.dict2D =   nfwlet2D(nframe=self.nframe,ngrid=self.nx,smooth_scale=-1)\n",
    "# 2) From Surface Density of Excess Surface Density\n",
    "self.ks2D   =   massmap_ks2D(self.ny,self.nx)\n",
    "\n",
    "# 3) Lening Kernel: from Excess Surface Density to Shear\n",
    "\n",
    "if self.nlp<=1:\n",
    "    self.lensKernel =   np.ones((self.nz,self.nlp))\n",
    "else:\n",
    "    self.lensKernel =   np.zeros((self.nz,self.nlp))\n",
    "    for i,zs in enumerate(zsbin):\n",
    "        self.lensKernel[i,:]    =   self.cosmo.deltacritinv(zlbin,zs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf{D^{1,2}}$ refer to difference operators in two transverse  (ra, dec) directions. $\\lambda_2$ control the amplitude of the Total Square Variance (TSV) term.\n",
    "\n",
    "\n",
    "```python\n",
    "# sparseBase.massmapSparsityTask.gradient_TSV\n",
    "# Definition of D1 and D2\n",
    "dalphaR =   np.zeros(self.shapeA)\n",
    "difx    =   np.roll(self.alphaR[:,0,:,:],1,axis=-1)\n",
    "difx    =   difx-self.alphaR[:,0,:,:] # D1\n",
    "dify    =   np.roll(self.alphaR[:,0,:,:],1,axis=-2)\n",
    "dify    =   dify-self.alphaR[:,0,:,:] # D2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate out the second order terms in the loss function.\n",
    "$$F(\\vec{x})=\\frac{1}{2}(y_{i}-A^{*}_{ij}x_{j})(y_{i}-A_{ik}x_{k})+\\frac{\\lambda_2}{2}[(D^{1}_{ij} x_{j})(D^{1}_{ik}x_{k})+ (D^{2}_{ij} x_{j})(D^{2}_{ik}x_{k})],$$\n",
    "\n",
    "Then we approach to the minimum of the loss function ($L(\\vec{x})$) by iteratively updates each component of $\\vec{x}$\n",
    "$$x_{\\alpha}^{(n+1)}=x_{\\alpha}-S_{\\lambda_1 \\sigma_{\\alpha}}(\\mu \\frac{\\partial_{\\alpha}F(\\vec{x})}{A_{i\\alpha}A_{i\\alpha}+4\\lambda_2}),$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\partial_\\alpha F(\\vec{x})=-A_{i\\alpha}^{*} (y_{i}-A_{ij}x_{j}) + \\lambda_2(D^1_{i\\alpha}D^1_{ij} x_{j}+ D^2_{i\\alpha} D^2_{ij} x_j).$$\n",
    "\n",
    "$\\mu$ is the step size of the iteration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "# sparseBase.massmapSparsityTask.gradient\n",
    "# calculate the gradient of the Second order component in loss function \n",
    "# wihch includes Total Square Variance(TSV) and chi2 components\n",
    "gCh2=self.gradient_chi2()\n",
    "gTSV=self.gradient_TSV()\n",
    "\n",
    "# sparseBase.massmapSparsityTask.gradient_chi2\n",
    "# calculate the gradient of the chi2 component\n",
    "shearRTmp   =   self.main_forward(self.alphaR) #A_{ij} x_j\n",
    "self.shearRRes   =   self.shearR-shearRTmp     #y_i-A_{ij} x_j\n",
    "dalphaR     =   -self.main_transpose(self.shearRRes)/2. #-A_{i\\alpha}(y_i-A_{ij} x_j)/2\n",
    "\n",
    "# sparseBase.massmapSparsityTask.gradient_TSV\n",
    "gradx   =   np.roll(difx,-1,axis=-1)\n",
    "gradx   =   gradx-difx    # (D1)_{i\\alpha} (D1)_{ij} x_j\n",
    "grady   =   np.roll(dify,-1,axis=-2)  \n",
    "grady   =   grady-dify    # (D2)_{i\\alpha} (D2)_{ij} x_j\n",
    "dalphaR[:,0,:,:]=(gradx+grady)*self.lbd2/2.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that here $A_{i\\alpha} A_{i\\alpha}$ should be estimated taking into account the mask of observed shear field.\n",
    "```python\n",
    "# sparseBase.massmapSparsityTask.spectrum_norm\n",
    "# Estimate A_{i\\alpha} A_{i\\alpha}\n",
    "asquareframe=np.zeros((self.nz,self.nframe,self.ny,self.nx))\n",
    "for iz in range(self.nz):\n",
    "    maskF=np.fft.fft2(self.mask[iz,:,:])\n",
    "    for iframe in range(self.nframe):\n",
    "        fun=np.abs(self.ks2D.transform(self.dict2D.fouaframes[iframe,:,:],outFou=False))**2.\n",
    "        asquareframe[iz,iframe,:,:]=np.fft.ifft2(np.fft.fft2(fun).real*maskF).real\n",
    "\n",
    "spectrum=np.sum(self.lensKernel[:,:,None,None,None]*asquareframe[:,None,:,:,:],axis=0)\n",
    "self.mu=0.8/(spectrum+4.*self.lbd2) #we chose mu=0.8\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import cosmology\n",
    "import numpy as np\n",
    "import astropy.io.fits as pyfits\n",
    "\n",
    "try:\n",
    "    import lsst.log as logging\n",
    "    import lsst.afw.image as afwImage\n",
    "    import lsst.afw.display as afwDisplay\n",
    "    afwDisplay.setDefaultBackend('firefly')\n",
    "    haslsst=True\n",
    "except ImportError:\n",
    "    haslsst=False\n",
    "from configparser import ConfigParser\n",
    "    \n",
    "\n",
    "def zMeanBin(zMin,dz,nz):\n",
    "    return np.arange(zMin,zMin+dz*nz,dz)+dz/2.\n",
    "\n",
    "\n",
    "# LASSO Threshold Functions\n",
    "def soft_thresholding(dum,thresholds):\n",
    "    # Standard Threshold Function\n",
    "    return np.sign(dum)*np.maximum(np.abs(dum)-thresholds,0.)\n",
    "\n",
    "def firm_thresholding(dum,thresholds):\n",
    "    # I do not understand\n",
    "    mask    =   (np.abs(dum)<= thresholds)\n",
    "    dum[mask]=  0.\n",
    "    mask    =   (np.abs(dum)>thresholds)\n",
    "    mask    =   mask&(np.abs(dum)<= 2*thresholds)\n",
    "    dum[mask]=  np.sign(dum[mask])*(2*np.abs(dum[mask])-thresholds[mask])\n",
    "    return dum\n",
    "\n",
    "def my_thresholding(dum,thresholds):\n",
    "    # doesnot work @_@\n",
    "    mask    =   (abs(dum)<= thresholds)\n",
    "    dum[mask]=  0.\n",
    "    mask    =   (abs(dum)>thresholds)\n",
    "    dum[mask]=  np.sign(dum[mask])*(abs(dum[mask])-thresholds[mask]**2./abs(dum[mask]))\n",
    "    return dum\n",
    "\n",
    "class massmap_ks2D():\n",
    "    def __init__(self,ny,nx):\n",
    "        self.shape   =   (ny,nx)\n",
    "        self.e2phiF  =   self.e2phiFou(self.shape)\n",
    "\n",
    "    def e2phiFou(self,shape):\n",
    "        ny1,nx1 =   shape\n",
    "        e2phiF  =   np.zeros(shape,dtype=complex)\n",
    "        for j in range(ny1):\n",
    "            jy  =   (j+ny1//2)%ny1-ny1//2\n",
    "            jy  =   jy/ny1\n",
    "            for i in range(nx1):\n",
    "                ix  =   (i+nx1//2)%nx1-nx1//2\n",
    "                ix  =   ix/nx1\n",
    "                if (i**2+j**2)>0:\n",
    "                    e2phiF[j,i]    =   np.complex((ix**2.-jy**2.),2.*ix*jy)/(ix**2.+jy**2.)\n",
    "                else:\n",
    "                    e2phiF[j,i]    =   1.\n",
    "        return e2phiF*np.pi\n",
    "\n",
    "    def itransform(self,gMap,inFou=True,outFou=True):\n",
    "        assert gMap.shape==self.shape\n",
    "        if not inFou:\n",
    "            gMap =   np.fft.fft2(gMap)\n",
    "        kOMap    =   gMap/self.e2phiF*np.pi\n",
    "        if not outFou:\n",
    "            kOMap    =   np.fft.ifft2(kOMap)\n",
    "        return kOMap\n",
    "\n",
    "    def transform(self,kMap,inFou=True,outFou=True):\n",
    "        assert kMap.shape==self.shape\n",
    "        if not inFou:\n",
    "            kMap =   np.fft.fft2(kMap)\n",
    "        gOMap    =   kMap*self.e2phiF/np.pi\n",
    "        if not outFou:\n",
    "            gOMap    =   np.fft.ifft2(gOMap)\n",
    "        return gOMap\n",
    "\n",
    "class massmapSparsityTask():\n",
    "    def __init__(self,sources,parser):\n",
    "        #display\n",
    "        self.display_irun=30\n",
    "        self.display_izl=0\n",
    "        self.display_iframe=0\n",
    "        #file\n",
    "        assert parser.has_option('file','pixDir'), 'Do not have pixDir'\n",
    "        self.pixDir   =   parser.get('file','pixDir')\n",
    "        assert parser.has_option('file','frameDir'), 'Do not have frameDir'\n",
    "        self.frameDir =   parser.get('file','frameDir')\n",
    "        assert parser.has_option('file','lbdDir'), 'Do not have lbdDir'\n",
    "        self.lbdDir   =   parser.get('file','lbdDir')\n",
    "        if parser.has_option('file','fieldN'):\n",
    "            self.fieldN =   parser.get('file','fieldN')\n",
    "        else:\n",
    "            self.fieldN  =   'test'\n",
    "\n",
    "        #sparse\n",
    "        self.lbd    =   parser.getfloat('sparse','lbd')\n",
    "        if parser.has_option('sparse','lbd2'):\n",
    "            self.lbd2   =   parser.getfloat('sparse','lbd2')\n",
    "        else:\n",
    "            self.lbd2   =   0.\n",
    "        self.nframe =   parser.getint('sparse','nframe')\n",
    "        self.nMax   =   parser.getint('sparse','nMax')\n",
    "        self.maxR   =   parser.getint('sparse','maxR')\n",
    "        outFname    =   'deltaMap_lbd%.1f_%s.fits' %(self.lbd,self.fieldN)\n",
    "        self.outFname   =   os.path.join(self.lbdDir,outFname)\n",
    "\n",
    "        #transverse plane\n",
    "        if parser.has_option('transPlane','raname'):\n",
    "            self.raname     =   parser.get('transPlane','raname')\n",
    "        else:\n",
    "            self.raname     =   'ra'\n",
    "        if parser.has_option('transPlane','decname'):\n",
    "            self.decname    =   parser.get('transPlane','decname')\n",
    "        else:\n",
    "            self.decname    =   'dec'\n",
    "        self.xMin   =   parser.getfloat('transPlane','xMin')\n",
    "        self.yMin   =   parser.getfloat('transPlane','yMin')\n",
    "        self.scale  =   parser.getfloat('transPlane','scale')\n",
    "        self.ny     =   parser.getint('transPlane'  ,'ny')\n",
    "        self.nx     =   parser.getint('transPlane'  ,'nx')\n",
    "\n",
    "        #lens z axis\n",
    "        self.nlp    =   parser.getint('lensZ','nlp')\n",
    "        if self.nlp<=1:\n",
    "            self.zlMin  =   0.\n",
    "            self.zlscale=   1.\n",
    "        else:\n",
    "            self.zlMin       =   parser.getfloat('lensZ','zlMin')\n",
    "            self.zlscale     =   parser.getfloat('lensZ','zlscale')\n",
    "        zlBin       =   zMeanBin(self.zlMin,self.zlscale,self.nlp)\n",
    "\n",
    "        #source z axis\n",
    "        if parser.has_option('sourceZ','zname'):\n",
    "            self.zname      =   parser.get('sourceZ','zname')\n",
    "        else:\n",
    "            self.zname      =   'z'\n",
    "\n",
    "        self.nz     =   parser.getint('sourceZ','nz')\n",
    "        if self.nz<=1:\n",
    "            self.zMin   =   0.01\n",
    "            self.zscale =   2.5\n",
    "        else:\n",
    "            self.zMin   =   parser.getfloat('sourceZ','zMin')\n",
    "            self.zscale =   parser.getfloat('sourceZ','zscale')\n",
    "        zsBin       =   zMeanBin(self.zMin,self.zscale,self.nz)\n",
    "\n",
    "        self.shapeS =   (self.nz,self.ny,self.nx)\n",
    "        self.shapeL =   (self.nlp,self.ny,self.nx)\n",
    "        self.shapeA =   (self.nlp,self.nframe,self.ny,self.nx)\n",
    "\n",
    "        self.cosmo  =   cosmology.Cosmo(h=1)\n",
    "        lensKName   =   os.path.join(self.pixDir,'lensKernel.fits')\n",
    "        if os.path.exists(lensKName):\n",
    "            self.lensKernel =   pyfits.getdata(lensKName)\n",
    "            assert self.lensKernel.shape==   (self.nz,self.nlp), 'load wrong lensing kernel'\n",
    "        else:\n",
    "            self.lensing_kernel(zlBin,zsBin)\n",
    "            pyfits.writeto(lensKName,self.lensKernel)\n",
    "\n",
    "        dicname =   parser.get('sparse','dicname')\n",
    "        if dicname=='starlet':\n",
    "            from halolet import starlet2D\n",
    "            self.dict2D =   starlet2D(gen=2,nframe=self.nframe,ny=self.ny,nx=self.nx)\n",
    "        elif dicname=='nfwlet':\n",
    "            from halolet import nfwlet2D\n",
    "            self.dict2D =   nfwlet2D(nframe=self.nframe,ngrid=self.nx,smooth_scale=-1)\n",
    "        self.ks2D   =   massmap_ks2D(self.ny,self.nx)\n",
    "\n",
    "        # Read pixelized shear and mask\n",
    "        g1Fname     =   os.path.join(self.pixDir,'g1Map_%s.fits'%self.fieldN)\n",
    "        g2Fname     =   os.path.join(self.pixDir,'g2Map_%s.fits'%self.fieldN)\n",
    "        nFname      =   os.path.join(self.pixDir,'nMap_%s.fits'%self.fieldN)\n",
    "        assert os.path.exists(nFname),'cannot find pixelized shear, run binSplit first'\n",
    "        self.nMap   =   pyfits.getdata(nFname)\n",
    "        g1Map       =   pyfits.getdata(g1Fname)\n",
    "        g2Map       =   pyfits.getdata(g2Fname)\n",
    "        assert self.nMap.shape  ==   self.shapeS, 'load wrong pixelized shear'\n",
    "        self.mask   =   (self.nMap>=0.1)\n",
    "\n",
    "        # Estimate mu\n",
    "        self.spectrum_norm()\n",
    "\n",
    "        # Estimate variance plane for alpha\n",
    "        sigFname    =   os.path.join(self.frameDir,'sigmaAlpha_%s.fits' %self.fieldN)\n",
    "        sigma_noise =   parser.getfloat('sparse','sigma_noise')\n",
    "        if os.path.exists(sigFname):\n",
    "            self.sigmaA =   pyfits.getdata(sigFname)\n",
    "            assert self.sigmaA.shape  ==   self.shapeA, 'load wrong noise sigma map'\n",
    "        else:\n",
    "            self.prox_sigmaA(100,sigma_noise)\n",
    "            pyfits.writeto(sigFname,self.sigmaA)\n",
    "            \n",
    "        \n",
    "        # Initialization\n",
    "        self.alphaR =   np.zeros(self.shapeA)   # alpha\n",
    "        self.deltaR =   np.zeros(self.shapeL)   # delta\n",
    "        self.shearRRes   = np.zeros(self.shapeS)# shear residuals\n",
    "        self.shearR =   g1Map+np.complex128(1j)*g2Map # shear\n",
    "        return\n",
    "\n",
    "    def lensing_kernel(self,zlbin,zsbin):\n",
    "        logging.info('Calculating lensing kernel')\n",
    "        if self.nlp<=1:\n",
    "            self.lensKernel =   np.ones((self.nz,self.nlp))\n",
    "        else:\n",
    "            self.lensKernel =   np.zeros((self.nz,self.nlp))\n",
    "            for i,zs in enumerate(zsbin):\n",
    "                self.lensKernel[i,:]    =   self.cosmo.deltacritinv(zlbin,zs)\n",
    "        return\n",
    "\n",
    "    def main_forward(self,alphaRIn):\n",
    "        shearOut    =   np.zeros(self.shapeS,dtype=np.complex128)\n",
    "        for zl in range(self.nlp):\n",
    "            deltaFZl=   self.dict2D.itransform(alphaRIn[zl,:,:,:],inFou=False)\n",
    "            shearRZl=   self.ks2D.transform(deltaFZl,outFou=False)\n",
    "            shearOut+=  (self.lensKernel[:,zl,None,None]*shearRZl)\n",
    "        shearOut    =   shearOut*(self.mask.astype(np.int))\n",
    "        return shearOut\n",
    "\n",
    "    def main_transpose(self,shearRIn):\n",
    "        deltaFTmp       =   np.zeros(self.shapeL,dtype=np.complex128)\n",
    "        for zs in range(self.nz):\n",
    "            kappaFZs    =   self.ks2D.itransform(shearRIn[zs],inFou=False)\n",
    "            deltaFTmp  +=   (self.lensKernel[zs,:,None,None]*kappaFZs)\n",
    "        alphaRO         =   np.empty(self.shapeA)\n",
    "        for zl in range(self.nlp):\n",
    "            alphaRO[zl,:,:,:]=self.dict2D.itranspose(deltaFTmp[zl],outFou=False).real\n",
    "        return alphaRO\n",
    "\n",
    "    def gradient_chi2(self):\n",
    "        # sparseBase.massmapSparsityTask.gradient_chi2\n",
    "        # calculate the gradient of the chi2 component\n",
    "        shearRTmp   =   self.main_forward(self.alphaR) #A_{ij} x_j\n",
    "        self.shearRRes   =   self.shearR-shearRTmp     #y_i-A_{ij} x_j\n",
    "        dalphaR     =   -self.main_transpose(self.shearRRes)/2. #-A_{i\\alpha}(y-A_{ij} x_j)/2\n",
    "        return dalphaR\n",
    "\n",
    "    def gradient_TSV(self):\n",
    "        # sparseBase.massmapSparsityTask.gradient_TSV\n",
    "        # calculate the gradient of the Total Square Variance(TSV) component\n",
    "        \n",
    "        # Initialization\n",
    "        dalphaR =   np.zeros(self.shapeA)\n",
    "        \n",
    "        difx    =   np.roll(self.alphaR[:,0,:,:],1,axis=-1)\n",
    "        difx    =   difx-self.alphaR[:,0,:,:] #D1\n",
    "        gradx   =   np.roll(difx,-1,axis=-1)\n",
    "        gradx   =   gradx-difx # (D1)_{i\\alpha} (D1)_{ij} x_j\n",
    "\n",
    "        dify    =   np.roll(self.alphaR[:,0,:,:],1,axis=-2)\n",
    "        dify    =   dify-self.alphaR[:,0,:,:] #D2\n",
    "        grady   =   np.roll(dify,-1,axis=-2)\n",
    "        grady   =   grady-dify # (D2)_{i\\alpha} (D2)_{ij} x_j\n",
    "        dalphaR[:,0,:,:]=(gradx+grady)*self.lbd2/2.\n",
    "        return dalphaR\n",
    "\n",
    "    def gradient(self):\n",
    "        # sparseBase.massmapSparsityTask.gradient\n",
    "        # calculate the gradient of the Second order component in loss function \n",
    "        # wihch includes Total Square Variance(TSV) and chi2 components\n",
    "        gCh2=self.gradient_chi2()\n",
    "        gTSV=self.gradient_TSV()\n",
    "        return gCh2+gTSV\n",
    "\n",
    "    def spectrum_norm(self):\n",
    "        # sparseBase.massmapSparsityTask.spectrum_norm\n",
    "        # Estimate A_{i\\alpha} A_{i\\alpha}\n",
    "        asquareframe=np.zeros((self.nz,self.nframe,self.ny,self.nx))\n",
    "        for iz in range(self.nz):\n",
    "            maskF=np.fft.fft2(self.mask[iz,:,:])\n",
    "            for iframe in range(self.nframe):\n",
    "                fun=np.abs(self.ks2D.transform(self.dict2D.fouaframes[iframe,:,:],outFou=False))**2.\n",
    "                asquareframe[iz,iframe,:,:]=np.fft.ifft2(np.fft.fft2(fun).real*maskF).real\n",
    "\n",
    "        spectrum=np.sum(self.lensKernel[:,:,None,None,None]*asquareframe[:,None,:,:,:],axis=0)\n",
    "        spectrum[:,0,:,:]=spectrum[:,0,:,:]+4.*self.lbd2 \n",
    "        self.mu=0.05/spectrum#we chose mu=0.8\n",
    "        return\n",
    "\n",
    "    def prox_sigmaA(self,niter,sigma):\n",
    "        logging.info('Estimating sigma map')\n",
    "        outData     =   np.zeros(self.shapeA)\n",
    "        if sigma<=0:\n",
    "            logging.info('using mock catalog to calculate alpha sigma')\n",
    "            simSrcName  =   os.path.join(self.pixDir,'mock_RG_grid_%s.npy' %(self.fieldN))\n",
    "            simSrc      =   np.load(simSrcName)\n",
    "            for irun in range(niter):\n",
    "                shearSim    =   simSrc[irun]\n",
    "                alphaRSim   =   self.main_transpose(shearSim)\n",
    "                outData     +=  alphaRSim**2.\n",
    "        else:\n",
    "            sigMap  =   np.zeros(self.shapeS)\n",
    "            sigMap[self.mask]  =   sigma/np.sqrt(self.nMap[self.mask])\n",
    "            for irun in range(niter):\n",
    "                np.random.seed(irun)\n",
    "                g1Sim   =   np.random.randn(self.nz,self.ny,self.nx)*sigMap\n",
    "                g2Sim   =   np.random.randn(self.nz,self.ny,self.nx)*sigMap\n",
    "                shearSim=   g1Sim+np.complex128(1j)*g2Sim\n",
    "                alphaRSim=  self.main_transpose(shearSim)\n",
    "                outData +=  alphaRSim**2.\n",
    "                \n",
    "        maskL =   (np.sum(self.nMap,axis=0)>1.)\n",
    "        for izlp in range(self.nlp):\n",
    "            for iframe in range(self.nframe):\n",
    "                outData[izlp,iframe][~maskL]=np.max(outData[izlp,iframe])\n",
    "        self.sigmaA =   self.mu*np.sqrt(outData/niter)\n",
    "\n",
    "        \n",
    "        imgShow3=afwImage.ImageF(self.ny,self.nx)\n",
    "        imgShow3.getArray()[:,:]=self.sigmaA[self.display_izl,self.display_iframe,:,:]\n",
    "        display3 = afwDisplay.Display(frame=7)\n",
    "        display3.mtv(imgShow3,title='sigma')\n",
    "        imgShow3=afwImage.ImageF(self.ny,self.nx)\n",
    "        imgShow3.getArray()[:,:]=outData[self.display_izl,self.display_iframe,:,:]\n",
    "        display3 = afwDisplay.Display(frame=10)\n",
    "        display3.mtv(imgShow3,title='outData')\n",
    "        return\n",
    "\n",
    "    def reconstruct(self):\n",
    "        #update deltaR\n",
    "        for zl in range(self.nlp):\n",
    "            alphaRZ         =   self.alphaR[zl].copy()\n",
    "            self.deltaR[zl] =   self.dict2D.itransform(alphaRZ,inFou=False,outFou=False)/self.zlscale\n",
    "        return\n",
    "\n",
    "    def run_main_iteration(self,iup,niter,threM='FT'):\n",
    "        tn=0\n",
    "        self.thresholds =   self.lbd*self.sigmaA\n",
    "        for irun in range(niter):\n",
    "            #save old kappaFou\n",
    "            dalphaR =   -self.mu*self.gradient().real\n",
    "            dum     =   self.alphaR.real+dalphaR\n",
    "            if threM=='FT':\n",
    "                dum  = firm_thresholding(dum,self.thresholds)\n",
    "            elif threM=='ST':\n",
    "                dum  = soft_thresholding(dum,self.thresholds)\n",
    "            elif threM=='MT':\n",
    "                dum  = my_thresholding(dum,self.thresholds)\n",
    "            #update tn and get ratio\n",
    "            tnTmp= (1.+np.sqrt(1.+4*tn**2.))/2.\n",
    "            ratio= (tn-1.)/tnTmp\n",
    "            tn   = tnTmp\n",
    "            self.alphaR=dum+(ratio*(dum-self.alphaR))\n",
    "            # Display the fits file using lsst.afw.display and firefly backend\n",
    "            if irun in range(self.display_irun-1, self.display_irun+1):\n",
    "                begFrame=(1+irun-self.display_irun)*3\n",
    "                imgShow=afwImage.ImageF(self.ny,self.nx)\n",
    "                imgShow.getArray()[:,:]=self.alphaR.real[self.display_izl,self.display_iframe,:,:]\n",
    "                display = afwDisplay.Display(frame=begFrame)\n",
    "                display.mtv(imgShow,title='alpha-%s' %irun)\n",
    "                imgShow=afwImage.ImageF(self.ny,self.nx)\n",
    "                imgShow.getArray()[:,:]=dalphaR[self.display_izl,self.display_iframe,:,:]\n",
    "                display = afwDisplay.Display(frame=begFrame+1)\n",
    "                display.mtv(imgShow,title='dalpha-%s' %irun)\n",
    "                self.reconstruct()\n",
    "                imgShow=afwImage.ImageF(self.ny,self.nx)\n",
    "                imgShow.getArray()[:,:]=self.deltaR[self.display_izl,:,:]\n",
    "                display = afwDisplay.Display(frame=begFrame+2)\n",
    "                display.mtv(imgShow,title='delta-%s' %irun)\n",
    "        return\n",
    "\n",
    "    def process(self,niter=51):\n",
    "        self.thresholdsMin  =   self.lbd*self.sigmaA\n",
    "        threM   =   'ST'\n",
    "        self.run_main_iteration(0,niter,threM)\n",
    "        self.reconstruct()\n",
    "        return\n",
    "\n",
    "    def write(self):\n",
    "        pyfits.writeto(self.outFname,self.deltaR.real,overwrite=True)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lustre2/work/xiangchong.li/massMapSim/stampSim/oneHalo-2D/TSV-lbd1.5\n"
     ]
    }
   ],
   "source": [
    "cd ./wrkDir/stampSim/oneHalo-2D/TSV-lbd1.5/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "configName  =   'config_lbd8_m9_z9.ini'\n",
    "srcFname    =   'src_'+configName.split('.')[0]+'.fits'\n",
    "parser      =   ConfigParser()\n",
    "parser.read(configName)\n",
    "sources     =   pyfits.getdata(srcFname)\n",
    "\n",
    "sparse3D    =   massmapSparsityTask(sources,parser)\n",
    "sparse3D.process()\n",
    "#sparse3D.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-51eea9a5b399>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mimgShow3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mafwImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse3D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msparse3D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdisplay3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mafwDisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mimgShow3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse3D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mdisplay3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmtv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgShow3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'show'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "# A_{i\\alpha} A_{i\\alpha}\n",
    "asquareframe=np.zeros((sparse3D.nz,sparse3D.nframe,sparse3D.ny,sparse3D.nx))\n",
    "for iz in range(sparse3D.nz):\n",
    "    maskF=np.fft.fft2(sparse3D.mask[iz,:,:])\n",
    "    for iframe in range(sparse3D.nframe):\n",
    "        fun=np.abs(sparse3D.ks2D.transform(sparse3D.dict2D.fouaframes[iframe,:,:],outFou=False))**2.\n",
    "        asquareframe[iz,iframe,:,:]=np.fft.ifft2(np.fft.fft2(fun).real*maskF).real\n",
    "\n",
    "spectrum=np.sum(sparse3D.lensKernel[:,:,None,None,None]*asquareframe[:,None,:,:,:],axis=0)+4.*sparse3D.lbd2\n",
    "imgShow3=afwImage.ImageF(sparse3D.ny,sparse3D.nx)\n",
    "display3 = afwDisplay.Display(frame=10)\n",
    "imgShow3.getArray()[:,:]=sparse3D.thresholds[0,1,:,:]\n",
    "display3.mtv(imgShow3,title='show')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0cd683d64442>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse3D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msparse3D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msparse3D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msparse3D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mny\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msparse3D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse3D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minFou\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse3D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mks2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutFou\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse3D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mks2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minFou\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "a=np.zeros((sparse3D.nframe,sparse3D.ny,sparse3D.nx))\n",
    "a[1,sparse3D.ny//2,sparse3D.nx//2]=1.\n",
    "a=sparse3D.dict2D.itransform(a,inFou=False)\n",
    "a=sparse3D.ks2D.transform(a,outFou=False)\n",
    "a=sparse3D.ks2D.itransform(a,inFou=False)\n",
    "a=sparse3D.dict2D.itranspose(a,outFou=False).real\n",
    "print(np.sum(a[1,24,24]**2.))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse3D.lbd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
